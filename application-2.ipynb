{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application 2: Analysis of candidate reference standard materials\n",
    "\n",
    "This is the code to generate the results and figures for the application 2 published in **(ADD DOI)**\n",
    "\n",
    "In this example we perform data curation as a first step for a suite of plasma candidate reference materials. PCA score plots are generated before and after curation to evaluate the data, in particular temporal drift and dispersion of the QC samples.\n",
    "\n",
    "The curation strategy used consists in:\n",
    "\n",
    "1. Discard features with retention time values lower than 90 seconds, as the system dead time was approximately 0.8 minutes.\n",
    "2. Discard features that were not present in all pooled QC samples as a condition for performing the LOESS-batch correction.\n",
    "3. if a feature had a peak area in a plasma sample that was 10-fold or less than the maximum peak area in the solvent, zero volume injection, and sample preparation blanks of the same feature, then its peak area was set to 0. Otherwise, the mean peak area in those blanks was subtracted from the feature peak areas in the plasma samples. In this way, potential contaminants and signals from the solvent would be removed for further analysis.\n",
    "4. Filter based on the relative standard deviation of the feature in pooled QC samples was applied. That is, all features with a RSD>20% in pooled QC sample injections were eliminated. Median absolute deviation was used as an unbiased estimate of the standard deviation by multiplying by a scaling factor, as a robust estimate of RSD.\n",
    "5. A 100% intraclass prevalence filter was subsequently applied with a threshold area value of 5; i.e., all area values below this threshold were considered as zero.\n",
    "6. The prevalence filter was followed by the D-ratio filter, estimated as the median absolute deviation considering pooled QC samples over the MAD considering all samples. This filter was used to remove features with zero or low biological information, setting an acceptance criterion to D-ratio values lower than 10%, and leading to a final data matrix composed of 665 metabolic features.\n",
    "\n",
    "At the end of the data curation pipeline the 665-feature matrix was normalized by using the total area of each \n",
    "\n",
    "\n",
    "**The batch correction is the most computing intensive step, with running times of ~ 10 min using a Personal Computer with an 8th generation Intel i5 processor and 8 GiB memory.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tidyms as ms\n",
    "import bokeh.plotting\n",
    "bokeh.plotting.output_notebook()\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "from adjustText import adjust_text\n",
    "from download_from_metabolights import get_application2_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the data is available.\n",
    "get_application2_data(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "data_matrix_path = \"data/NIST001.csv\"\n",
    "data = ms.fileio.read_progenesis(data_matrix_path)\n",
    "\n",
    "# add order and batch information\n",
    "data.add_order_from_csv(\"data/run-order-data.csv\")\n",
    "\n",
    "# rename classes from 1, 2,... to SRM1, SRM2, ...\n",
    "class_mapping = {\"1\": \"RM1\", \"2\": \"RM2\", \"3\": \"RM3\", \"4\": \"SRM4\",\n",
    "                 \"QC\": \"QC\", \"Z\": \"Z\", \"SCQC\": \"SCQC\",\n",
    "                 \"B\": \"B\", \"SSS\": \"SSS\", \"SV\": \"SV\"}\n",
    "data.classes = data.sample_metadata[\"class\"].map(class_mapping)\n",
    "\n",
    "# set sample mapping\n",
    "sample_mapping = {\"qc\": [\"QC\"],\n",
    "                  \"blank\": [\"SV\",\"B\", \"Z\"],\n",
    "                  \"sample\": [\"RM1\", \"RM2\", \"RM3\", \"SRM4\"],\n",
    "                  \"suitability\": [\"SSS\"]}\n",
    "data.mapping = sample_mapping\n",
    "\n",
    "# set plot mode to seaborn\n",
    "data.set_plot_mode(\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a custom filter to remove features based on retention time\n",
    "class RTFilter(ms.filter.Processor):\n",
    "    \n",
    "    def __init__(self, min_rt=None, max_rt=None, verbose=False):\n",
    "        super(RTFilter, self).__init__(\"filter\", \"features\", verbose=verbose)\n",
    "        if min_rt is None:\n",
    "            min_rt = 0\n",
    "        if max_rt is None:\n",
    "            max_rt = np.inf\n",
    "        self.params = {\"min_rt\": min_rt, \"max_rt\": max_rt}\n",
    "        \n",
    "    def func(self, dc):\n",
    "        rt = dc.feature_metadata[\"rt\"]\n",
    "        min_rt = self.params[\"min_rt\"]\n",
    "        max_rt = self.params[\"max_rt\"]\n",
    "        invalid_rt = (rt < min_rt) | (rt > max_rt)\n",
    "        rm_features = rt[invalid_rt].index\n",
    "        return rm_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4\n",
    "PCA score plots on Study and QC samples before data curation. Data is mean centered and scaled to unitary variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_classes = [\"Z\", \"SV\", \"B\", \"SCQC\", \"SSS\"]\n",
    "palette = [\"#8bcde8ff\", \"#e54042ff\", \"#efbf33ff\", \"#455d7aff\", \"#a7b3bdff\"]\n",
    "g = data.plot.pca_scores(ignore_classes=ignore_classes,\n",
    "                         relplot_params={\"hue_order\": [\"QC\", \"RM1\", \"RM2\", \"RM3\", \"SRM4\"], \"s\": 50,\n",
    "                                         \"palette\": palette},\n",
    "                         scaling=\"autoscaling\")\n",
    "\n",
    "# use adjust_text to label each point\n",
    "ax = g.axes[0, 0]\n",
    "scores, _, _, _ = data.metrics.pca(scaling=\"autoscaling\", ignore_classes=ignore_classes)\n",
    "qc_samples_index = data.classes.isin([\"QC\"])\n",
    "qc_samples_index = qc_samples_index[qc_samples_index].index\n",
    "pc1 = scores.loc[qc_samples_index, \"PC1\"].values\n",
    "pc2 = scores.loc[qc_samples_index,\"PC2\"].values\n",
    "order = data.order[qc_samples_index]\n",
    "text = [ax.text(pc1[i], pc2[i], str(order[i]), ha='center', va='center') for i in range(pc1.size)]\n",
    "adjust_text(text);\n",
    "# g.savefig(\"pca-before.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure S4 (a)\n",
    "\n",
    "PCA score plots on QC samples before data curation. Data is normalizad to total area, mean centered and scaled to unitary variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_classes = [\"Z\", \"SV\", \"B\", \"SCQC\", \"SSS\",\n",
    "                  \"RM1\", \"RM2\", \"RM3\", \"SRM4\"]\n",
    "g = data.plot.pca_scores(ignore_classes=ignore_classes,\n",
    "                         scaling=\"autoscaling\", normalization=\"sum\")\n",
    "\n",
    "# use adjust_text to label each point\n",
    "ax = g.axes[0, 0]\n",
    "scores, _, _, _ = data.metrics.pca(scaling=\"autoscaling\", \n",
    "                                   normalization=\"sum\",\n",
    "                                   ignore_classes=ignore_classes)\n",
    "pc1 = scores[\"PC1\"].values\n",
    "pc2 = scores[\"PC2\"].values\n",
    "order = data.order[scores.index].values\n",
    "text = [ax.text(pc1[i], pc2[i], str(order[i]), ha='center', va='center') for i in range(pc1.size)]\n",
    "adjust_text(text)\n",
    "# g.savefig(\"pca-qc-before.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# remove the last three blank samples\n",
    "rmsamples = [\"NZ_20200227_095\", \"NZ_20200227_097\", \"NZ_20200227_099\"]\n",
    "data.remove(rmsamples, axis=\"samples\")\n",
    "\n",
    "# building a data curation pipeline\n",
    "\n",
    "# remove features with rt lower than 90 seconds\n",
    "rt_filter = RTFilter(min_rt=90)\n",
    "# correct instrumental signal drift\n",
    "batch_corrector = ms.filter.BatchCorrector(min_qc_dr=0.8, first_n_qc=3,\n",
    "                                           method=\"additive\")\n",
    "# blank correction\n",
    "blank_corrector = ms.filter.BlankCorrector(mode=\"max\", factor=10)\n",
    "# remove blank and conditioning QC samples\n",
    "class_filter = ms.filter.ClassRemover([\"B\",\"SV\",\"SSS\",\"SCQC\",\"Z\"])\n",
    "# remove features high a %RSD higher than 20 % in the QC samples\n",
    "vf = ms.filter.VariationFilter(ub=0.2, robust=True)\n",
    "# remove features that are not detected in all study samples\n",
    "pf = ms.filter.PrevalenceFilter(lb=1, threshold=5)\n",
    "# remove features with low biological variation\n",
    "drf= ms.filter.DRatioFilter(ub=0.1, robust=True)\n",
    "\n",
    "# Build and apply the data curation pipeline\n",
    "processors = [rt_filter, batch_corrector, blank_corrector, class_filter,\n",
    "              vf, pf, drf]\n",
    "pipeline = ms.filter.Pipeline(processors, verbose=True)\n",
    "pipeline.process(data)\n",
    "\n",
    "# normalize to total signal intensity\n",
    "data.preprocess.normalize(method=\"sum\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save(\"data/nist001-curated.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load curated data to bypass curation step\n",
    "data = ms.DataContainer.from_pickle(\"data/nist001-curated.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.metrics.cv(robust=True, fill_value=0).loc[\"QC\"].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4\n",
    "PCA score plots on Study and QC samples after data curation. Data is normalized, mean centered and scaled to unitary variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = [\"#8bcde8ff\", \"#e54042ff\", \"#efbf33ff\", \"#455d7aff\", \"#a7b3bdff\"]\n",
    "g = data.plot.pca_scores(scaling=\"autoscaling\", normalization=\"sum\",\n",
    "                         relplot_params={\"hue_order\": [\"QC\", \"RM1\", \"RM2\", \"RM3\", \"SRM4\"],\n",
    "                                         \"palette\": palette, \"s\": 50})\n",
    "# g.savefig(\"pca-after.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure S4 (b)\n",
    "\n",
    "PCA score plots on QC samples after data curation. Data is normalizad to total area, mean centered and scaled to unitary variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_classes = [\"SRM1\", \"SRM2\", \"SRM3\", \"SRM4\"]\n",
    "g = data.plot.pca_scores(ignore_classes=ignore_classes,\n",
    "                         scaling=\"autoscaling\")\n",
    "\n",
    "# use adjust_text to label each point\n",
    "ax = g.axes[0, 0]\n",
    "scores, _, _, _ = data.metrics.pca(scaling=\"autoscaling\", \n",
    "                                   normalization=\"sum\",\n",
    "                                   ignore_classes=ignore_classes)\n",
    "pc1 = scores[\"PC1\"].values\n",
    "pc2 = scores[\"PC2\"].values\n",
    "order = data.order[scores.index].values\n",
    "text = [ax.text(pc1[i], pc2[i], str(order[i]), ha='center', va='center') for i in range(pc1.size)]\n",
    "adjust_text(text);\n",
    "# g.savefig(\"pca-qc-after.png\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
